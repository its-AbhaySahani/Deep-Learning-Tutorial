{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8cdbe62",
   "metadata": {},
   "source": [
    "\n",
    "# Compute Average of Numbers in an RDD using PySpark with flatMap\n",
    "\n",
    "This notebook demonstrates how to calculate the average of a list of numbers using PySpark with the `flatMap` transformation. \n",
    "The `compute_average_flatmap` function transforms each RDD element into a sequence of `(sum, count)` pairs.\n",
    "\n",
    "## Steps Involved\n",
    "1. Parallelize the list into an RDD.\n",
    "2. Use `flatMap` to convert each number into a `(1, (number, 1))` pair for aggregation.\n",
    "3. Use `reduceByKey` to sum up the values and counts.\n",
    "4. Calculate the average by dividing the total sum by the count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634305fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "def split_names(sc, full_names):\n",
    "    # Parallelize the list into an RDD\n",
    "    rdd = sc.parallelize(full_names)\n",
    "    \n",
    "    # Use flatMap to split each full name into first and last name\n",
    "    # For each full name, flatMap will return a list of individual names\n",
    "    split_rdd = rdd.flatMap(lambda name: name.split(\" \"))\n",
    "    \n",
    "    # Collect the results\n",
    "    result = split_rdd.collect()\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    sc = SparkContext.getOrCreate()\n",
    "    names = [\"John Doe\", \"Jane Smith\", \"Alice Johnson\"]\n",
    "    result = split_names(sc, names)\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
